[{"body":"\rThe requirement was to propose projects that address\none or more environmental challenges we face across the globe today using Project AIR.\nTIBCO LABS IoT and sustainability Hack\r\r.fix{\rtransform: rotate(-8deg);\rposition: fixed;\rz-index: 1000;\rleft: 48em;\rtop: 6em;\r}\r#clockdiv{\rfont-family: sans-serif;\rcolor: #fff;\rdisplay: inline-block;\rfont-weight: 100;\rtext-align: center;\rfont-size: 20px;\r}\r#clockdiv  div{\rpadding: 6px;\rborder-radius: 3px;\rbackground: #1774e5;\rdisplay: inline-block;\r}\r#clockdiv div  span{\rpadding: 10px;\rborder-radius: 3px;\rbackground: #0e4f9e;\rdisplay: inline-block;\r}\r.smalltext{\rpadding-top: 5px;\rfont-size: 12px;\r}\r#targetdate {\rtext-align: center;\rfont-size: 60px;\rmargin-top: 0px;\r}\r\r\r\rDays\r\r\r\rHours\r\r\r\rMinutes\r\r\r\rSeconds\r\r\r\rfunction getTimeRemaining(endtime) {\rconst total = Date.parse(endtime) - Date.parse(new Date());\rconst seconds = Math.floor((total / 1000) % 60);\rconst minutes = Math.floor((total / 1000 / 60) % 60);\rconst hours = Math.floor((total / (1000 * 60 * 60)) % 24);\rconst days = Math.floor(total / (1000 * 60 * 60 * 24));\rreturn {total,days,hours,minutes,seconds};\r}\rfunction initializeClock(id, endtime) {\rconst clock = document.getElementById(id);\rconst daysSpan = clock.querySelector('.days');\rconst hoursSpan = clock.querySelector('.hours');\rconst minutesSpan = clock.querySelector('.minutes');\rconst secondsSpan = clock.querySelector('.seconds');\rfunction updateClock() {\rconst t = getTimeRemaining(endtime);\rdaysSpan.innerHTML = t.days;\rhoursSpan.innerHTML = ('0' + t.hours).slice(-2);\rminutesSpan.innerHTML = ('0' + t.minutes).slice(-2);\rsecondsSpan.innerHTML = ('0' + t.seconds).slice(-2);\rif (t.total \nFrom enhancing energy efficiency and reducing global emissions to making cities “smarter,” the Internet of Things (IoT) and sustainability are natural partners, so please focus your submissions on this combination. Be creative, and remember that while submissions can target suggestions such as those that follow, you can also propose other ideas.\nWinners\n First Place: AI-Based Crop Management System, https://www.youtube.com/watch?v=gRKB9f1SiPU Second Place: Project Sonora, https://www.youtube.com/watch?v=uAYgIvGcOIM\u0026t=9s Third Place: Flux, https://www.youtube.com/watch?v=qX7wwf9MWbw  Thanks for participating!\n","excerpt":"\rThe requirement was to propose projects that address\none or more …","ref":"/labs-air/docs/hackathon/","title":"Hackathon"},{"body":"With Project AIR, you can register and interact with IoT Device Farm to process derived data anywhere that is needed and store the data as needed to analyze and address a large number of analytical use cases extending any layer of its architecture as needed. Connect your IoT Device Farm and take action in TIBCO’s connected intelligence cloud.\nArchitecture A sneak peek of AIR’s architecture, more details coming soon.\nFully open platform that can run anywhere to support the digitalization of the real world.\n Register and Interact with IoT Devices Process IoT Data Regardless of Source Compute at the Edge  Infrastructure Cloud Agnostic Deployment\n AWS Azure * GCP * On-Prem *   Note: * = Runs on pre-existing Kubernetes cluster\n Technology Stack Edge to Cloud Ecosystem\n Edge Cloud  Extension Points System Pluggability\n Edge Data Endpoints UI Data Stores  GitHub Repositories TIBCO LABS Project AIR consist of multiple Repos full Query here.\nHere a quick Introduction …\n  labs-air\nstores the Project Site and Documentation\n  labs-air-ui\nAIR user Interface implemented using Angular.io\n  labs-air-edgex\nconfigurations of EdgeX Foundry releated to AIR\n  labs-air-charts\nbootstraps a Project Air deployment on a Kubernetes cluster using the Helm package manager.\n  labs-air-services\nAIR platform backend and edge services based on TIBCO Flogo\n  labs-air-contrib\nAIR platform releated TIBCO Flogo extensions, connectors, and functions\n    ","excerpt":"With Project AIR, you can register and interact with IoT Device Farm …","ref":"/labs-air/docs/overview/","title":"Overview"},{"body":"Prerequisites MacOs  Linux  Windows   MacOs Recommended: Version v11.6 Big Sur\r* Docker Desktop: 20.10.8\r Linux Recommended: Ubuntu v20.04.3 LTS\r* Docker: 20.10.9\r* Docker Compose: 1.28.2\r Windows Recommended: Version 10 Pro\r* Docker Desktop: 20.10.8\r   Got more questions? please check the Advance Installation Tips section below or reach out on tibcolabs@tibco.com\n helpful URL’s some helpful URL’s to find your way quickly\n https://docs.docker.com/get-docker/   Note: we try to review those in time. Let us know in case a link is broken!\n Install Project AIR Locally TIBCO LABS Project AIR latest Release Site here\nMacOs  Linux  Windows   1. Download the darwin artifacts from the latest release site\r2. Extract the artifacts and go to the extracted folder\r3. Run the following command:\r./install.sh\r Download the linux artifacts from the latest release site\r1. Extract the artifacts and go to the extracted folder\r2. Run the following command:\r./install.sh\r Download the windows artifacts from the latest release site\r2. Extract the artifacts and go to the extracted folder\r3. Run the following command as Administrator:\rcall install.cmd\r  After all the processes are done you see the following 3 docker compose groups in your docker dashboard\nNow you can access project air UI by typing: http - localhost:8081 in your browser locally.\n Got more questions? please check the Advance Installation Tips section below or reach out on tibcolabs@tibco.com\n Delete Project AIR Locally MacOs  Linux  Windows   1. Download the darwin artifacts from the latest release site\r2. Extract the artifacts and go to the extracted folder\r3. Run the following command:\r./remove.sh\r Download the linux artifacts from the latest release site\r1. Extract the artifacts and go to the extracted folder\r2. Run the following command:\r./remove.sh\r Download the windows artifacts from the latest release site\r2. Extract the artifacts and go to the extracted folder\r3. Run the following command as Administrator:\rcall remove.cmd\r  Advanced installer tips \n","excerpt":"Prerequisites MacOs  Linux  Windows   MacOs Recommended: Version v11.6 …","ref":"/labs-air/docs/gettingstarted/","title":"Getting Started"},{"body":"Introduction Once a Device Grouping has been discovered by project AIR, a connection has been established with edge devices. In this section we show how to configure Messaging Protocos, Data Stores and ML Model connections which can be used in Data Pipelines to receive, process data from devices, and publish device data to other edge or cloud applications. The following steps will guide you through the configuration of messaging protocols, data stores and ML models connections.\nPrerequisites Prerequisite 1: Edgex Edgex is a vendor neutral open source platform at the edge of the network that interacts with physical devices, sensors, actuators and other IoT objects. It enables the interoperability between devices and applications at the edge and at the cloud. Edgex will be installed as part of the AIR installation.\n Edgex  Every running Edgex platform uses an internal messaging bus to move data through the different layers at the edge. From a running instance of Edgex, gather the following information:\n Transport used: MQTT, ZeroMQ or Redis Connection URL Connection credentials  Prerequisite 2: AIR Project AIR installation provides a messaging broker for sending data from edge devices to wherever the AIR infrastructure is running (in premise, cloud). The messaging infrastructure is used by AIR core components and also can be used by any application requiring to receive data from edge devices and data flows.\nFrom a running AIR installation, gather the following information:\n Transport used: MQTT, Kafka or TCM Connection URL Connection credentials  The following tables provide default connection details for the basic demo example.\nEdgex MQTT    Property Value     Hostname edgex-mqtt-broker   Port 1883   Topic edgexevents   Username    Password     AIR MQTT    Property Value     Hostname mosquitto   Port 31883   Topic EdgexGatewayData   Username mqtt_admin   Password mqtt_admin    AIR Notifications MQTT    Property Value     Hostname mosquitto   Port 31883   Topic EdgexGatewayNotification   Username mqtt_admin   Password mqtt_admin    Prerequisite 3: Data Store Information Device data can be stored in one or several data stores depending on the use case requirements. Gather the following information for each data store:\n Connection URL Connection Credentials  Prerequisite 3: Data Store Table Setup For each required data store, the user needs to configure the data store and create tables to store the data. Project AIR provides scripts with SQL commands to create the required artifacts.\nFollowing is an example sql script to create the artifact for a Postgres Database. Postgres SQL script\nAccessing Endpoints Configuration Step 1: From the Gateways page, select the Device Group you want to configure. Step 2: Click the Endpoints Configuration Icon. Step 3: The Endpoint configuration page should be displayed. Adding Messaging Protocols Step 1: Select the desired protocol from the pulldown menu under the Protocol Details panel Step 2: Enter required information for the selected protocol Step 2: Click the Add Protocol button. The new protocol configuration should be shown in the Inbound Protocols panel Adding Data Stores Step 1: Click the Data Stores tab Step 2: Select the desired data store from the pulldown menu under the DataStore Details panel Step 3: Enter required information for the selected data store Step 4: Click the Add Data Store button. The new data store configuration should be shown in the Data Stores panel Note that before using the data store in a pipeline, the AIR required tables need to be setup. Project AIR provides scripts for the creation of the required tables for all the different data stores. See pre-requisites section for details.\nAdding ML Model Connections Step 1: Click the Models tab Step 2: Enter the model information under the Model Details panel Scope: select either GLOBAL or GATEWAY:\n GLOBAL means the connection will be available and visible to all the pipeline configuration across GATEWAY means the connection will be visible only to the pipelines in the current gateway.  Name: is the name of the model connection\nURL: is the address of the model’s REST interface.\nInput Template: allow users to provide a json schema definition of the input the model is expecting. Project air provides template keys that allow device data to be mapped to the required fields in the model.\nDescription: allow users to provide a description of what the model does. This information will be available to users when configuring pipelines.\nStep 3: Enter required information for the model connection Step 4: Click the Add Model button. The new model connection configuration should be shown in the Models panel ","excerpt":"Introduction Once a Device Grouping has been discovered by project …","ref":"/labs-air/docs/userguide/configuringendpoints/","title":"Configuring Endpoints"},{"body":"Introduction Project AIR provides device adapters to allow end users to simulate generation of events and readings without having any real devices.\nThe events and reading go to the Edgex core data micro services and propagated to project AIR pipelines.\nREST Device This device service provides easy way for any application to push data into EdgeX via the REST protocol.\nThe service provides the following resources for simulating data of different data types:\n int16_reading - simulates a resource/sensor generating integer readings float32_reading - simulates a resource/sensor generating float readings bool_reading - simulates a resource/sensor generating boolean readings str_reading - simulates a resource/sensor generating string readings image_reading - simulates a resource/sensor generating image readings  REST Endpoints This device service provides the following REST endpoints:\nhttp://:49565/api/v1/resource/RESTDevice/{resourceName}\nresourceNamerefers to the device resource names listed above.\nTesting/Simulation The best way to test this service with simulated data is to use PostMan to send data to the following endpoints.\nhttp://localhost:49565/api/v1/resource/RESTDevice/image_reading\nPOSTing an image file (jpeg or png) will result in the BinaryValue of the Reading being set to the JPEG/PNG image data posted. Example test JPEG to post: Select any JPEG file from your computer or the internet\nhttp://localhost:49565/api/v1/resource/RESTDevice/int16_reading\nPOSTing a text integer value will result in the Value of the Reading being set to the string representation of the value as an Int16. The POSTed value is verified to be a valid Int16 value.\nA 400 error will be returned if the POSTed value fails the Int16 type verification.\nExample test int value to post:\n1001\nhttp://localhost:49565/api/v1/resource/RESTDevice/float32_reading\nPOSTing a text float value will result in the Value of the Reading being set to the string representation of the value as an Float32. The POSTed value is verified to be a valid Float32 value.\nA 400 error will be returned if the POSTed value fails the Float32 type verification.\nExample test float value to post:\n500.56\nhttp://localhost:49565/api/v1/resource/RESTDevice/bool_reading\nPOSTing a text boolean value will result in the Value of the Reading being set to the string representation of the value as a Bool. The POSTed value is verified to be a valid boolean value.\nA 400 error will be returned if the POSTed value fails the Boolean type verification.\nExample test boolean value to post:\ntrue\nhttp://localhost:49565/api/v1/resource/RESTDevice/str_reading\nPOSTing a text value will result in the Value of the Reading being set as a string.\nExample test string value to post:\nabc\nMQTT Device This device service provides easy way for any application to push data into EdgeX via the MQTT protocol.\nThe device service connects a MQTT topic to EdgeX acting like a device/sensor feed.\nThe service provides the following resources for simulating data of different data types:\n int16_reading - simulates a resource/sensor generating integer readings float32_reading - simulates a resource/sensor generating float readings bool_reading - simulates a resource/sensor generating boolean readings str_reading - simulates a resource/sensor generating string readings image_reading - simulates a resource/sensor generating image readings  MQTT Topic This device subscribes to a MQTT Topic (/generic/event). When a value is received it passes to the Edgex core data micro services and propagated to project AIR pipelines.\nThe following examples illustrate the json message required for sending data for the above described resources.\n{“deviceName”:“MQTTDevice”,“resourceName”:“int16_reading”,“int16_reading”:100}\n{“deviceName”:“MQTTDevice”,“resourceName”:“float32_reading”,“float32_reading”:100.0}\n{“deviceName”:“MQTTDevice”,“resourceName”:“str_reading”,“str_reading”:“test1”}\n{“deviceName”:“MQTTDevice”,“resourceName”:“bool_reading”,“bool_reading”:true}\n","excerpt":"Introduction Project AIR provides device adapters to allow end users …","ref":"/labs-air/docs/userguide/devicesimulators/","title":"Device Simulators"},{"body":"Introduction Projet AIR pipeline editor is a wizard driven tool that allows you to create data pipelines or data flows. Each pipeline represents specific business logic in an app. A pipeline or data flow contains one or more activities.\nThe pipelines allow you to implement the business logic as a process. You can visually design the flows using the UI. A pipeline can consist of one or more activities that perform a specific task. Activities are linked in order to facilitate the flow of data between them. The pipeline execution is started by a subscriber.\nThe following activities are available by default in all pipelines. It consists of subscribers, activities and publishers that may be commonly used by any pipeline. A subscriber initiates the pipeline in which it appears. An activity is used to perform a task on the data received by a subscriber. A publisher is used publish data to other pipelines or to other systems.\nData Subscriber Data Subscriber is used to receive events and activate a pipeline. Events are originated from IoT devices.\nData Subscriber receive IoT events from data sources such as MQTT, Kafka, AMQP and so on.\nProject AIR pipelines receive events with the following JSON schema which is propagated through all the pipeline.\nAfter adding a subscriber activity, you must configure it with the transport protocol from the list of configured protocols.\n{ \"$schema\": \"http://json-schema.org/draft-04/schema#\", \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"string\" }, \"origin\": { \"type\": \"number\" }, \"device\": { \"type\": \"string\" }, \"gateway\": { \"type\": \"string\" }, \"readings\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"string\" }, \"origin\": { \"type\": \"number\" }, \"device\": { \"type\": \"string\" }, \"name\": { \"type\": \"string\" }, \"value\": { \"type\": \"string\" } } } } } } Filter When creating a flow, you may want to filter out data from certain resources (sensors) or from certain devices. You can do this by adding a Filter activity in your flow and configure the Filter activity to filter specific devices and resources.\nFor events that meet the filter condition, the pipeline or flow will terminate. For events not meeting the filter condition, the flow will continue to the next activity.\nREST Service The REST activity is used to make a request to a REST service; it also accepts the reply returned by the service.\nInferencing The Inferencing activity is a REST Service activity customized to call ML Models exposed as REST serives. The service is configured using the Models Endpoints interface where users can provide the service URL and the input mappings for the service.\nResults from the inference service will be propagated through the pipeline as a new resource. The name of the new resource will postfixed with the word “Inferred”. For example, if the name of the resource used by the model is temperature, the name of the inferred result will be temperature_Inferred.\nData Publisher Data Publisher is used to send events originating from IoT devices to external applications or other pipelines.\nData Publisher sends IoT events to message brokers such as MQTT, Kafka, AMQP and so on.\nData Publisher uses the same schema as received by the Data Subscriber.\nAfter adding a Data Publisher activity, you must configure it with the transport protocol from the list of configured protocols.\nRules The Rules activity is used to implement basic rules on data coming from IoT devices.\nA Rule constitutes of multiple Conditions and the rule triggers when all its conditions pass.\nA Condition is an expression involving data from the IoT device. When the expression evaluates to true, the condition passes.\nA Action is a function that is invoked each time the evaluation of all its conditions is true.\nOne of the actions of the Rules activity is a notification. The notification can be send to external application by using the Notification Publisher activity.\nStreaming IoT devices have the potential for producing millions or even billions of events at rapid intervals, often times the events on their own are meaningless, hence the need to provide basic streaming operations against the slew of events.\nThe Streaming activity provides the following functionality:\nEnables apps to implement basic streaming constructs in a simple pipeline fashion Provides non-persistent state for streaming operations Streams are persisted in memory until the end of the pipeline Serves as a pre-process pipeline for raw data to perform basic mathematical and logical operations. Ideal for feeding ML models Filter out the noise with stream filtering capabilities\nAfter adding a Streaming activity, you must configure it with the desired device resource to stream, the operation to use to aggregate events, and the type of aggregation window to use.\nData Store The Data Store activity enables users to run SQL insert operation on several supported data stores like Postgres, Oracle, Snoflake, MySQL, etc, and store IoT device data to the selected data store.\nAfter adding a Data Store activity, you must configure it with the desired data store from the list of configured data stores.\nNotification Publisher The Notification Publisher activity allows users to send notification messages to external applications. The activity can be placed after activities generating notifications like the Rule activity. All the notifications generated by the activity will be routed to the Notification activity and send to external applications using the pre-configured messaging protocol.\nFlogo Flow TIBCO Labs Project AIR pipelines allow users to import TIBCO Flogo applications and be deployed to the edge as any other project AIR pipeline.\nAfter adding a Flogo Flow activity, you must configure it with the desired service port and the json file containing the Flogo App configuration. The user can also overrride properties values exposed by the Flogo application.\n","excerpt":"Introduction Projet AIR pipeline editor is a wizard driven tool that …","ref":"/labs-air/docs/userguide/pipelineactivities/","title":"Pipeline Activities"},{"body":"Introduction TIBCO Project AIR enables users to configure flows/business logic with data from edge devices. Users can configure a Data Pipeline (Data Flow) to sequence, filter, stream data and specify a data store based on your business logic. A typical pipeline configuration consists of activities that define the messaging protocol to receive data, define operations on the data (filtering, streaming, inferencing, rules) and the data stores. This section will guide you through all the steps required to create data pipelines.\nArchitecture Overview Every AIR deployment consist of edge components (devices, edge framework), as well as components that can be colocated at the edge, on premise, or on a private or public clooud. Devices interact with whole AIR infrastructure through Edgex adapters providing the device’s required communication protocol and data standard. Data traverse through the Edgex layers using an internal Edgex messaging protocol (i.e. MQTT). Data is standardized and converted into a common schema which can then be used by any application at the Edgex Service Layer (.ie. AIR Pipelines). AIR Pipelines can be configured from the provided UI which can be running locally or remotely. Pipelines are configured to recieve/subscribe standardized data from devices using the provided Edgex internal messaging protocol, filter, stream, infer, apply rules to the data and then publish the data to other applications. Data can be published to AIR applications or other pipelines running at the edge or at the cloud. Applications can use the messaging protocol (i.e. MQTT) provided by AIR infrastructure. Once the pipelines are configured, pipelines are converted into Flogo Applications, compiled to the desired platform, conteinerized and then deployed.\nPrerequisites Prerequisite 1: Device Groups Configuration Before you begin, make sure the messaging protocols, data stores and models configuration for device groups have been configured. See here. See Configuring Device Groups.\nAdding Data Pipelines Step 1: Open Pipeline Editor From the Gateways page, select the Device Group you want to configure and click Pipeline Editor Icon.\nStep 2: The Pipelines Editor page should be displayed. Step 3: Subscribe to device events On the editor canvas, right click and select the Data Subscriber activity.\nMost data pipelines start subscribing to events coming from devices. The Data Subscriber activity allows users to select the source of the device data.\nStep 4: Configure Data Subscriber On the activity configuration panel, select and review the messaging protocol\nAll the messaging protocols that have previously been configured in the Device Groups Configuration will be available for selection. Select the source for device events.\nStep 5: Filter device data (Optional) Select the devices to filter by selecting the Filter Activity.\nData can be filtered from going through the pipeline. Right click on the editor canvas and select Filters.\nStep 6: Configure filter activity On the activity configuration panel, select device and resource (sensors) data to be filtered. Only the sensor data/resources non-selected in the list will be propagated through the pipeline. Connect activities by selecting the connection ports.\nStep 7: Publish device data On the editor canvas, right click and select the Data Publisher activity.\nDevice data can be published to any messaging protocol that has been previously configured in the Device Groups connection pages.\nStep 8: Configure Data Publisher On the activity configuration panel, select and review the messaging protocol\nAll the messaging protocols that have previously been configured in the Device Groups Configuration will be available for selection. Select the destination for device events.\nStep 9: Name and Save Data Pipeline. After entering pipeline name, deployment target and deployer type, save the pipeline configuration. The configuration can then be deployed to a Kubernetes cluster either local or on the cloud.\nDeploying Data Pipelines Once data pipelines have been configured, they can be deployed dynamically to Kubernetes cluster running locally or on the cloud.\nStep 1: Select the desired pipeline from the Pipelines table and then click Deploy Pipeline Step 2: The pipeline is deployed and should show the Status as Ready/Deployed Verifying Data Pipelines Deployment After a pipeline is deployed from the UI, a Docker container is started in the deployment target machine. There are several ways to verify the container is up and running. In this section we will use Docker Desktop to verify and inspect the deployed contianer.\nStep 1: Note Id of deployed Pipeline After the pipeline is deployed, a new entry will be shown in the pipelines table. Note the id of the pipeline as that will be used to identify the running container.\nStep 2: Open Docker Dashboard Open Docker Dashboard UI and select the Containers/Apps tab. A list of all running containers is shown.\nStep 3: Inspect Container From the list of containers, select and open the container matching the Id noted in Step1.\nStep 4: Viewing Container Logs After container is selected, select the LOGS tab to view the container logs.\nStep 5: Viewing Container Stats From selected container panel, select the STATS tab to review container’s cpu usage, memory usage, etc.\nUpdeploying Data Pipelines If data from a device is not longer required or if needs to be modified, you can undeploy the pipeline. Undeploying will remove the engine processing the data from the Kubernetes cluster.\nStep 1: Select the desired pipeline from the Pipelines table and then click Undeploy Pipeline Step 2: The pipeline is undeployed and should show the Status as Undeployed/Saved Deleting Data Pipelines If data pipelines are not longer required, you can delete the pipeline. Notice that deployed pipelines can’t be deleted. They need to be undeployed first.\nStep 1: Select the desired pipeline from the Pipelines table and then click Delete Pipeline Step 2: The pipeline is deleted and should not appear in the Pipelines table. Subscribing to data published by Pipelines Data published by AIR pipelines is available to other pipelines or to any external application that has access to the AIR messaging infrastructure (i.e. MQTT). Applications with permissions to connect to the messaging infrastructure can subscribe to the published data. The following section provides the topic and schema of the data users need to use to receive data from AIR pipelines.\nTopic: EdgexGatewayData Message Schema: { \"type\": \"object\", \"title\": \"MQTTSubscriber\", \"properties\": { \"topic\": { \"type\": \"string\", \"required\": false }, \"retained\": { \"type\": \"boolean\", \"required\": false }, \"qos\": { \"type\": \"integer\", \"required\": false }, \"body\": { \"$schema\": \"http://json-schema.org/draft-04/schema#\", \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"string\" }, \"device\": { \"type\": \"string\" }, \"origin\": { \"type\": \"number\" }, \"gateway\": { \"type\": \"string\" }, \"readings\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"id\": { \"type\": \"string\" }, \"origin\": { \"type\": \"number\" }, \"device\": { \"type\": \"string\" }, \"name\": { \"type\": \"string\" }, \"value\": { \"type\": \"string\" } } } } } } } }    Property Description      Event represents a single measurable event read from a device. Event has a one-to-many relationship with Reading   id Uniquely identifies an event, for example a UUID   device Identifies the source of the event; the device’s name   origin A timestamp indicating when the original event/reading took place. Most of the time, this indicates when the device service collected/created the event   gateway Indicates the location or gateway where the event originated   readings A collection (one to many) of associated readings of a given event.   id Uniquely identifies a reading, for example a UUID   origin A timestamp indicating when the original event/reading took place. Most of the time, this indicates when the device service collected/created the event   device Identifies the source of the reading; the device’s name.   name name-value provide the key/value pair of what was sensed by a device. Name specifies what was the value collected. Name should match a device resource name in the device profile.   value The sensor data value    ","excerpt":"Introduction TIBCO Project AIR enables users to configure …","ref":"/labs-air/docs/userguide/datapipelines/","title":"Data Pipelines Details"},{"body":"List of Videos We created a list of short Introduction Videos for you to get a quick overview.\nFull Playlist on YouTube here\nGeneral Overview What is Project AIR about, a quick intro …\n UI Intro Overview of the User Interface\n Message Connections How to configure a Message Broker Connection, e.g. MQTT, Kafka, AMQP\n DS Connections How to configure a Data Store Connections e.g. to PostgreSQL, Snowflake, Oracle, MySQL, TIBCO Graph Database, Dgraph\n ML Model Connection How to create a Connection to a ML Model e.g. via REST\n Basic Pipe How to define a basic Data Flow to devices\n Basic Pipe Simulation Usage of simulation data for for devices\n Rule Pipe How to use a rule activity in a data flow\n Streaming Pipe How to use a streaming activity in a data flow\n Inferencing Pipe How to use a inferencing activity in a data flow, to call a ML model and return the results\n \n","excerpt":"List of Videos We created a list of short Introduction Videos for you …","ref":"/labs-air/docs/tutorials/","title":"Tutorials"},{"body":"TIBCO LABS Project AIR User Guide\n","excerpt":"TIBCO LABS Project AIR User Guide\n","ref":"/labs-air/docs/userguide/","title":"User Guide"},{"body":"\r--\rTIBCO LABS Project AIR Details\n","excerpt":"\r--\rTIBCO LABS Project AIR Details\n","ref":"/labs-air/docs/","title":"Documentation"},{"body":"","excerpt":"","ref":"/labs-air/blog/releases/","title":"New Releases"},{"body":"Installer Issues \rtoomanyrequests: Rate exceeded\rIf you are getting this error, it is likely that you are not logged in to docker.\nMake sure you are logged in to get more pull request limits.\ndocker login If the problem persists, please reach out to us.\n\r\n","excerpt":"Installer Issues \rtoomanyrequests: Rate exceeded\rIf you are getting …","ref":"/labs-air/docs/troubleshooting/","title":"Troubleshooting"},{"body":"Here you can find additional details and frequently asked questions\ndefault passwords  minikube docker/tcuser MQTT mosquitto/msquitto MQTT mqtt_admin/mqtt_admin  default ports  f1-proxy 5408 kong 8000,8001,8443,8444 kong-db 5432 edgex-mqtt-brocker 1883 edgex-vault 8200 edgex-redis 6379 edgex-consul 8500 AIR 10099 AIR-builder 10083 AIR-deployer 10082 AIR-projectmgr 10090, 10091 AIR-service-locator 10080, 10081  ","excerpt":"Here you can find additional details and frequently asked questions …","ref":"/labs-air/docs/cheat-sheet/","title":"Cheat Sheet"},{"body":"Complete makeover, include a new / “one-click” installation experience, new edge capabilities, and a new user experience! Create model-driven / real-time IoT data pipelines, incorporate AI/ML models (including computer vision), deploy everything to the edge, and more!\n check-out the new ‘Getting Started’ Section.\n ","excerpt":"Complete makeover, include a new / “one-click” installation …","ref":"/labs-air/blog/2021/11/01/november-21-release/","title":"November '21 Release"},{"body":"Update Release containing\n bug fixes performance enhancments security fixes 3rd party updates   please have a look back soon here.\n ","excerpt":"Update Release containing\n bug fixes performance enhancments security …","ref":"/labs-air/blog/2021/06/11/june-21-release/","title":"June '21 Release"},{"body":"More documentation Details got added, along with new features!\nWe support now Minikube and AWS Installations.\n please have a look back soon here.\n ","excerpt":"More documentation Details got added, along with new features!\nWe …","ref":"/labs-air/blog/2020/06/01/second-release/","title":"Second Release"},{"body":"first public Implementation of the TIBCO LABS™ Project AIR, containing:\n used EdgeX Foundry Assets TIBCO Flogo Services DGraph configurations ComputeDB Datastore configuration IoT UI as Cloud Starter Implementation Spotfire Dashboard   please have a look back soon here.\n ","excerpt":"first public Implementation of the TIBCO LABS™ Project AIR, …","ref":"/labs-air/blog/2020/02/26/initial-release/","title":"Initial Release"},{"body":"","excerpt":"","ref":"/labs-air/index.json","title":""},{"body":"\r\r#td-cover-block-0 {\rbackground-image: url(/labs-air/about/featured-background_hu0bf202e9b0c50adb82b333dd3f6f434d_393591_960x540_fill_q75_catmullrom_bottom.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-air/about/featured-background_hu0bf202e9b0c50adb82b333dd3f6f434d_393591_1920x1080_fill_q75_catmullrom_bottom.jpg); }\r}\r\rProject AIR by TIBCO LABS™\rBringing Simplified IoT and Edge Analytics Capabilities to EdgeX Foundry\r\r\r\r\r\r\r\rMore Details about this Initiative here TIBCO LABS™ Project Air Wiki, on \r\r\r\r--\r\rTIBCO LABS™ is a program designed to provide customers and partners with a mechanism for actively participating in TIBCO’s history of innovation.\rTIBCO has always been at the forefront of innovation, and TIBCO LABS™ allows participants to share in this history by collaboratively building solutions to today’s challenging problems, previewing new capabilities, and accessing emerging technologies in areas such as blockchain, AI / ML and IoT. Through TIBCO LABS™, customers and partners can gain insight into TIBCO’s innovation activities, participate in shaping the form of these activities in the years to come, and benefit from TIBCO’s leadership position in integration and analytics.\r\n\r\r\r\r\n\r\r\r\r\rBSD 3-Clause License \rCopyright © 2020 TIBCO Software Inc. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n  Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n  Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n  Neither the name of TIBCO Software Inc. nor the names of any contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT OWNER AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\r\r\r\r","excerpt":"\r\r#td-cover-block-0 {\rbackground-image: …","ref":"/labs-air/about/","title":"About Project AIR"},{"body":"This is the blog section. It has two categories: News and Releases.\nEntries in these directories are listed in reverse chronological order.\n","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/labs-air/blog/","title":"Blog"},{"body":"","excerpt":"","ref":"/labs-air/community/","title":"Community"},{"body":"\r\r#td-cover-block-0 {\rbackground-image: url(/labs-air/featured-background-org_hu54644cfbb8309b58f400117071f34abd_6110735_960x540_fill_q75_catmullrom_top.jpg); }\r@media only screen and (min-width: 1200px) {\r#td-cover-block-0 {\rbackground-image: url(/labs-air/featured-background-org_hu54644cfbb8309b58f400117071f34abd_6110735_1920x1080_fill_q75_catmullrom_top.jpg); }\r}\r\rProject AIR\rLearn More \r\rDownload \r\rIntelligent insights from device to boardroom\r\n\r\r\r\r\r\r\r\rProject AIR by TIBCO LABS™\nWith Project AIR, you can register and interact with IoT device farms to process IoT-derived data anywhere that is needed. Manipulate and analyze data as it arrives, store the results for further processing, and address a large number of IoT use cases by extending any layer of the architecture as needed. Connect to your IoT device farm with Project AIR and take further action in environments such as TIBCO’s Connected Intelligence Cloud.\n\r\r\r\rLatest News\nProject AIR now includes a new \"one-click\" installation experience, new edge capabilities, and a new user experience! Create model-driven / real-time IoT data pipelines, incorporate AI/ML models (including computer vision), deploy everything to the edge, and more!\nWe are excited about the new release, and are sure you will be as well!\n\n\r\r\r\r\r\r\rContact us!\rReach us for more details, or engage us today !\nRead more …\n\r\r\rContributions welcome!\rWe do a Pull Request contributions workflow on GitHub. New users are always welcome!\nRead more …\n\r\r\rFollow us on Twitter!\rFor announcement of latest features etc…\nRead more …\n\r\r\r\r","excerpt":"\r\r#td-cover-block-0 {\rbackground-image: …","ref":"/labs-air/","title":"Project AIR"},{"body":"","excerpt":"","ref":"/labs-air/search/","title":"Search Results"}]